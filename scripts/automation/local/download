#!/bin/bash

# --- 配置区 ---
NAME=$1
CLEAN_UP=true  # 设为 true 则在成功后删除 .aa, .ab 等分卷
# --------------

if [ -z "$NAME" ]; then
    echo "使用错误: ./download <release-name>"
    exit 1
fi

# 1. 处理文件名逻辑
# 输入: world-2026-01-14T20-32-17.761Z
# 输出目标: 2026-01-14T20-32-17.761Z.tar
TARGET_NAME="${NAME#world-}"  # 去掉 world- 前缀
TARGET_FILE="${TARGET_NAME}.tar"

# 2. 获取元数据
echo "正在获取 [$NAME] 的元数据及哈希值..."
gh release -R murolem/wplace-archives view "$NAME" --json assets | \
    jq -r '.assets[] | "\(.name)|\(.digest)|\(.url)"' > metadata_full.txt

awk -F'|' '{print $3}' metadata_full.txt > urls.txt

# 3. 循环下载
echo "开始多线程并行下载..."
until aria2c \
    -c \
    -i urls.txt \
    --max-connection-per-server=16 \
    --split=64 \
    --min-split-size=1M \
    --file-allocation=falloc \
    --disk-cache=128M \
    --lowest-speed-limit=100K \
    --stream-piece-selector=random \
    --uri-selector=feedback \
    --max-tries=10;
do
    echo "下载中断，3秒后重试..."
    sleep 3
done

# 4. 使用 parallel + openssl 进行硬件加速校验
echo "----------------------------------------------------"
echo "下载完成，正在并行校验分卷哈希 (OpenSSL 硬件加速)..."
echo "----------------------------------------------------"

do_verify() {
    line=$1
    fname=$(echo "$line" | cut -d'|' -f1)
    expected=$(echo "$line" | cut -d'|' -f2 | cut -d':' -f2)
    actual=$(openssl dgst -sha256 "$fname" | awk '{print $NF}')
    
    if [ "$actual" == "$expected" ]; then
        echo "✅ [PASS] $fname"
        return 0
    else
        echo "❌ [FAIL] $fname"
        return 1
    fi
}
export -f do_verify

cat metadata_full.txt | parallel --halt now,fail=1 do_verify {}

if [ $? -ne 0 ]; then
    echo "⚠️  校验失败，脚本停止。"
    exit 1
fi

# 5. 流式合并并解压 (GZ -> TAR)
# 找到分卷的公共前缀，例如：2026-01-14T20-32-17.761Z+3h23m.tar.gz
# 我们通过 metadata 找到实际的文件名模式
SAMPLE_FILE=$(head -n 1 metadata_full.txt | cut -d'|' -f1)
PREFIX_PATTERN="${SAMPLE_FILE%.*}" # 去掉最后的 .aa

echo "----------------------------------------------------"
echo "校验通过！正在流式合并并解压至 $TARGET_FILE ..."

# 核心逻辑：cat 所有分卷 | pigz(或gzip) 解压 > 目标tar
# 如果你安装了 pigz (多线程解压)，速度会更快，否则使用 gzip -d
DECOMPRESSOR="gzip -d -c"
if command -v pigz > /dev/null; then
    DECOMPRESSOR="pigz -d -c"
fi

cat "${PREFIX_PATTERN}."* | $DECOMPRESSOR > "$TARGET_FILE"

if [ $? -eq 0 ]; then
    echo "✅ 处理完成！"
    echo "最终结果: $(ls -lh "$TARGET_FILE")"
else
    echo "❌ 合并或解压过程中出错！"
    exit 1
fi

# 6. 可选清理
if [ "$CLEAN_UP" = true ]; then
    echo "正在清理分卷文件 (.aa, .ab...) ..."
    rm "${PREFIX_PATTERN}."*
    echo "✅ 清理完毕。"
else
    echo "⚠️  保留分卷文件。"
fi

rm metadata_full.txt urls.txt
echo "✨ 全部流程已圆满完成！"
